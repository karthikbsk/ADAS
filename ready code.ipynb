{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c9ae30",
   "metadata": {},
   "source": [
    "# Date time location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db0693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    # Combine location details\n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set resolution and frame rate (optional)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Live Camera Feed', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Live Camera Feed', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "last_update_time = time.time()\n",
    "update_interval = 3  # Update every 3 seconds\n",
    "display_index = 0\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    current_time = datetime.now().strftime('%H:%M:%S')\n",
    "    current_date = datetime.now().strftime('%d-%m-%Y')\n",
    "\n",
    "    # Update display content every `update_interval` seconds\n",
    "    if time.time() - last_update_time >= update_interval:\n",
    "        display_index = (display_index + 1) % 3  # Cycle through 0, 1, 2\n",
    "        last_update_time = time.time()\n",
    "\n",
    "    # Determine what to display\n",
    "    if display_index == 0:\n",
    "        text_to_display = current_time\n",
    "    elif display_index == 1:\n",
    "        text_to_display = current_date\n",
    "    else:\n",
    "        text_to_display = location_text\n",
    "\n",
    "    # Get the text size to calculate the position at the bottom right\n",
    "    text_size = cv2.getTextSize(text_to_display, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "\n",
    "    # Calculate position at the bottom right with added space\n",
    "    text_x = frame_width - text_size[0] - 10\n",
    "    text_y = frame_height - 10\n",
    "\n",
    "    cv2.putText(frame, text_to_display, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow('Live Camera Feed', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    return city, country\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set resolution and frame rate (optional)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Live Camera Feed', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Live Camera Feed', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "last_update_time = time.time()\n",
    "update_interval = 3  # Update every 3 seconds\n",
    "display_index = 0\n",
    "\n",
    "city, country = get_current_location()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    current_time = datetime.now().strftime('%H:%M:%S')\n",
    "    current_date = datetime.now().strftime('%d-%m-%Y')\n",
    "    location_text = f\"{city}, {country}\"\n",
    "\n",
    "    # Update display content every `update_interval` seconds\n",
    "    if time.time() - last_update_time >= update_interval:\n",
    "        display_index = (display_index + 1) % 3  # Cycle through 0, 1, 2\n",
    "        last_update_time = time.time()\n",
    "\n",
    "    # Determine what to display\n",
    "    if display_index == 0:\n",
    "        text_to_display = current_time\n",
    "    elif display_index == 1:\n",
    "        text_to_display = current_date\n",
    "    else:\n",
    "        text_to_display = location_text\n",
    "\n",
    "    # Get the text size to calculate the position at the bottom right\n",
    "    text_size = cv2.getTextSize(text_to_display, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "\n",
    "    # Calculate position at the bottom right with added space\n",
    "    text_x = frame_width - text_size[0] - 10\n",
    "    text_y = frame_height - 10\n",
    "\n",
    "    cv2.putText(frame, text_to_display, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow('Live Camera Feed', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14228042",
   "metadata": {},
   "source": [
    "# Head position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Initialize pyttsx3 engine for voice alerts\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def calculate_mar(mouth):\n",
    "    A = distance.euclidean(mouth[2], mouth[6])  # Vertical distance\n",
    "    B = distance.euclidean(mouth[3], mouth[5])  # Vertical distance\n",
    "    C = distance.euclidean(mouth[0], mouth[4])  # Horizontal distance\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# Define constants\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.7\n",
    "MOUTH_AR_CONSEC_FRAMES = 5\n",
    "YAWN_ALERT_CONSEC_FRAMES = 3\n",
    "DROWSY_ALERT_SECONDS = 20\n",
    "WARNING_DISPLAY_SECONDS = 10\n",
    "HEAD_POSITION_ALERT_SECONDS = 5\n",
    "COUNT_INTERVAL = 30  # Interval to update and display counts\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "consec_yawn_frames = 0\n",
    "last_yawn_count = 0\n",
    "increasing_yawn_streak = 0\n",
    "last_blink_update_time = time.time()\n",
    "count_update_time = time.time()  # Timer for counting interval\n",
    "\n",
    "warning_message = \"\"\n",
    "warning_start_time = 0\n",
    "head_position_start_time = None\n",
    "position = 'center'\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the resolution and frame rate to 720p\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
    "    with mp_face_detection.FaceDetection(min_detection_confidence=0.1) as face_detection:\n",
    "\n",
    "        def speak(message):\n",
    "            def speak_thread():\n",
    "                engine.say(message)\n",
    "                engine.runAndWait()\n",
    "            \n",
    "            threading.Thread(target=speak_thread).start()\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_height, frame_width = frame.shape[:2]\n",
    "            center_x, center_y = frame_width // 2, frame_height // 2\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(rgb_frame)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, _ = frame.shape\n",
    "                    bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                           int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    x, y, w, h = bbox\n",
    "                    \n",
    "                    # Check if bbox is valid\n",
    "                    if x < 0 or y < 0 or x + w > iw or y + h > ih:\n",
    "                        continue  # Skip to the next frame\n",
    "                    \n",
    "                    face_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "                    # Check if face_roi is valid\n",
    "                    if face_roi.size == 0:\n",
    "                        continue  # Skip to the next frame\n",
    "\n",
    "                    try:\n",
    "                        rgb_face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "                        face_mesh_results = face_mesh.process(rgb_face_roi)\n",
    "                    except cv2.error as e:\n",
    "                        print(f\"OpenCV error: {e}\")\n",
    "                        continue  # Skip to the next frame\n",
    "\n",
    "                    if face_mesh_results.multi_face_landmarks:\n",
    "                        for face_landmarks in face_mesh_results.multi_face_landmarks:\n",
    "                            landmarks = [(lm.x, lm.y) for lm in face_landmarks.landmark]\n",
    "                            landmarks = np.array(landmarks)\n",
    "\n",
    "                            # Update indices to use 468 landmarks\n",
    "                            left_eye = landmarks[36:42]\n",
    "                            right_eye = landmarks[42:48]\n",
    "                            mouth = landmarks[48:68]\n",
    "                            jawline = landmarks[0:17]  # Jawline (from 0 to 16)\n",
    "\n",
    "                            left_ear = eye_aspect_ratio(left_eye)\n",
    "                            right_ear = eye_aspect_ratio(right_eye)\n",
    "                            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "                            mar = calculate_mar(mouth)\n",
    "\n",
    "                            if ear < EYE_AR_THRESH:\n",
    "                                blink_frames += 1\n",
    "                            else:\n",
    "                                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                                    blink_count += 1\n",
    "                                blink_frames = 0\n",
    "\n",
    "                            if mar > MOUTH_AR_THRESH:\n",
    "                                yawn_frames += 1\n",
    "                            else:\n",
    "                                if yawn_frames >= MOUTH_AR_CONSEC_FRAMES:\n",
    "                                    yawn_count += 1\n",
    "                                    if yawn_count > last_yawn_count:\n",
    "                                        increasing_yawn_streak += 1\n",
    "                                    else:\n",
    "                                        increasing_yawn_streak = 0\n",
    "                                yawn_frames = 0\n",
    "\n",
    "                            last_yawn_count = yawn_count\n",
    "\n",
    "                            if increasing_yawn_streak >= YAWN_ALERT_CONSEC_FRAMES:\n",
    "                                warning_message = 'FATIGUE'\n",
    "                                warning_start_time = time.time()\n",
    "                                speak(\"You look fatigued, please take a break.\")\n",
    "                                increasing_yawn_streak = 0\n",
    "\n",
    "                            jaw_center_x = np.mean(jawline[:, 0] * iw)\n",
    "\n",
    "                            horizontal_threshold = 50\n",
    "\n",
    "                            if jaw_center_x < center_x - horizontal_threshold:\n",
    "                                position = 'left'\n",
    "                                if head_position_start_time is None:\n",
    "                                    head_position_start_time = time.time()\n",
    "                            elif jaw_center_x > center_x + horizontal_threshold:\n",
    "                                position = 'right'\n",
    "                                if head_position_start_time is None:\n",
    "                                    head_position_start_time = time.time()\n",
    "                            else:\n",
    "                                position = 'center'\n",
    "                                head_position_start_time = None\n",
    "\n",
    "                            if head_position_start_time and time.time() - head_position_start_time >= HEAD_POSITION_ALERT_SECONDS:\n",
    "                                warning_message = 'Look straight'\n",
    "                                warning_start_time = time.time()\n",
    "                                speak(\"Please look straight.\")\n",
    "                                head_position_start_time = None\n",
    "\n",
    "            current_time = time.time()\n",
    "\n",
    "            # Update and display counts every 30 seconds\n",
    "            if current_time - count_update_time >= COUNT_INTERVAL:\n",
    "                count_update_time = current_time\n",
    "\n",
    "            if current_time - last_blink_update_time >= DROWSY_ALERT_SECONDS:\n",
    "                warning_message = 'DROWSY'\n",
    "                warning_start_time = time.time()\n",
    "                speak(\"You appear drowsy, please stay alert.\")\n",
    "                last_blink_update_time = current_time\n",
    "\n",
    "            if warning_message and current_time - warning_start_time < WARNING_DISPLAY_SECONDS:\n",
    "                text_x = max(frame_width - 400, 10)\n",
    "                text_y = 100\n",
    "                cv2.putText(frame, warning_message, (text_x, text_y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)  # Smaller text size\n",
    "\n",
    "            # Display blink and yawn counts\n",
    "            cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Position: {position}', (10, 110),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Get current time and date\n",
    "            current_time = datetime.now().strftime('%H:%M:%S')\n",
    "            current_date = datetime.now().strftime('%d-%m-%Y')\n",
    "\n",
    "            # Combine time and date\n",
    "            time_date_text = f\"{current_time}\\n{current_date}\"\n",
    "\n",
    "            # Get the text size to calculate the position at the bottom right\n",
    "            text_size_time = cv2.getTextSize(current_time, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "            text_size_date = cv2.getTextSize(current_date, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "\n",
    "            # Calculate positions with added space between time and date\n",
    "            time_position = (frame_width - text_size_time[0] - 10, frame_height - text_size_date[1] - 50)  # Added space\n",
    "            date_position = (frame_width - text_size_date[0] - 10, frame_height - 10)\n",
    "\n",
    "            # Display the current time and date on the frame in red color\n",
    "            cv2.putText(frame, current_time, time_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, current_date, date_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af174c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jawline center X: 634.5503728529986\n",
      "Jawline center Y: 455.39602518081665\n",
      "Detected position: down\n",
      "Jawline center X: 651.2240802540499\n",
      "Jawline center Y: 465.9354897106395\n",
      "Detected position: down\n",
      "Jawline center X: 664.927054012523\n",
      "Jawline center Y: 469.0203696138719\n",
      "Detected position: down\n",
      "Jawline center X: 648.605759564568\n",
      "Jawline center Y: 456.36215560576494\n",
      "Detected position: down\n",
      "Jawline center X: 648.5885934268726\n",
      "Jawline center Y: 466.0983711130479\n",
      "Detected position: down\n",
      "Jawline center X: 645.4009089750402\n",
      "Jawline center Y: 459.128743760726\n",
      "Detected position: down\n",
      "Jawline center X: 652.0300001256606\n",
      "Jawline center Y: 456.750651808346\n",
      "Detected position: down\n",
      "Jawline center X: 634.2019025017233\n",
      "Jawline center Y: 458.0812887584462\n",
      "Detected position: down\n",
      "Jawline center X: 630.8657186171588\n",
      "Jawline center Y: 454.8031345535727\n",
      "Detected position: down\n",
      "Jawline center X: 632.6746458165786\n",
      "Jawline center Y: 454.06377638087554\n",
      "Detected position: down\n"
     ]
    }
   ],
   "source": [
    "# this head position code is perfect\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pyttsx3\n",
    "import threading\n",
    "import requests\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Initialize pyttsx3 engine for voice alerts\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def calculate_mar(mouth):\n",
    "    A = distance.euclidean(mouth[2], mouth[6])  # Vertical distance\n",
    "    B = distance.euclidean(mouth[3], mouth[5])  # Vertical distance\n",
    "    C = distance.euclidean(mouth[0], mouth[4])  # Horizontal distance\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "# Get current location once at the start\n",
    "location_text = get_current_location()\n",
    "\n",
    "# Define constants\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.7\n",
    "MOUTH_AR_CONSEC_FRAMES = 5\n",
    "YAWN_ALERT_CONSEC_FRAMES = 3\n",
    "DROWSY_ALERT_SECONDS = 20\n",
    "WARNING_DISPLAY_SECONDS = 10\n",
    "HEAD_POSITION_ALERT_SECONDS = 5\n",
    "COUNT_INTERVAL = 30  # Interval to update and display counts\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "consec_yawn_frames = 0\n",
    "last_yawn_count = 0\n",
    "increasing_yawn_streak = 0\n",
    "last_blink_update_time = time.time()\n",
    "count_update_time = time.time()  # Timer for counting interval\n",
    "\n",
    "warning_message = \"\"\n",
    "warning_start_time = 0\n",
    "head_position_start_time = None\n",
    "position = 'center'\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the resolution and frame rate to 720p\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
    "    with mp_face_detection.FaceDetection(min_detection_confidence=0.1) as face_detection:\n",
    "\n",
    "        def speak(message):\n",
    "            def speak_thread():\n",
    "                engine.say(message)\n",
    "                engine.runAndWait()\n",
    "            \n",
    "            threading.Thread(target=speak_thread).start()\n",
    "\n",
    "        last_update_time = time.time()\n",
    "        update_interval = 3  # Update every 3 seconds\n",
    "        display_index = 0\n",
    "\n",
    "        # Define landmarks for left and right eyes\n",
    "        LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "        RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "\n",
    "        # Define thresholds for head position detection\n",
    "        horizontal_threshold = 120\n",
    "        vertical_threshold = 90\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_height, frame_width = frame.shape[:2]\n",
    "            center_x, center_y = frame_width // 2, frame_height // 2\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(rgb_frame)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, _ = frame.shape\n",
    "                    bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                           int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    x, y, w, h = bbox\n",
    "                    \n",
    "                    if x < 0 or y < 0 or x + w > iw or y + h > ih:\n",
    "                        continue\n",
    "                    \n",
    "                    face_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "                    if face_roi.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        rgb_face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "                        face_mesh_results = face_mesh.process(rgb_face_roi)\n",
    "                    except cv2.error as e:\n",
    "                        print(f\"OpenCV error: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    if face_mesh_results.multi_face_landmarks:\n",
    "                        for face_landmarks in face_mesh_results.multi_face_landmarks:\n",
    "                            landmarks = [(lm.x, lm.y) for lm in face_landmarks.landmark]\n",
    "                            landmarks = np.array(landmarks)\n",
    "\n",
    "                            left_eye = landmarks[36:42]\n",
    "                            right_eye = landmarks[42:48]\n",
    "                            mouth = landmarks[48:68]\n",
    "                            jawline = landmarks[0:17]  # Jawline (from 0 to 16)\n",
    "\n",
    "                            left_ear = eye_aspect_ratio(left_eye)\n",
    "                            right_ear = eye_aspect_ratio(right_eye)\n",
    "                            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "                            mar = calculate_mar(mouth)\n",
    "\n",
    "                            if ear < EYE_AR_THRESH:\n",
    "                                blink_frames += 1\n",
    "                            else:\n",
    "                                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                                    blink_count += 1\n",
    "                                blink_frames = 0\n",
    "\n",
    "                            if mar > MOUTH_AR_THRESH:\n",
    "                                yawn_frames += 1\n",
    "                            else:\n",
    "                                if yawn_frames >= MOUTH_AR_CONSEC_FRAMES:\n",
    "                                    yawn_count += 1\n",
    "                                    if yawn_count > last_yawn_count:\n",
    "                                        increasing_yawn_streak += 1\n",
    "                                    else:\n",
    "                                        increasing_yawn_streak = 0\n",
    "                                yawn_frames = 0\n",
    "\n",
    "                            last_yawn_count = yawn_count\n",
    "\n",
    "                            if increasing_yawn_streak >= YAWN_ALERT_CONSEC_FRAMES:\n",
    "                                warning_message = 'You are fatigued, please be alert.'\n",
    "                                warning_start_time = time.time()\n",
    "                                speak(\"You look fatigued, please take a break.\")\n",
    "                                increasing_yawn_streak = 0\n",
    "\n",
    "                            # Calculate jawline center for head position detection\n",
    "                            jaw_center_x = np.mean(jawline[:, 0] * iw)\n",
    "                            jaw_center_y = np.mean(jawline[:, 1] * ih)\n",
    "\n",
    "                            # Debug prints for jawline center\n",
    "                            print(f\"Jawline center X: {jaw_center_x}\")\n",
    "                            print(f\"Jawline center Y: {jaw_center_y}\")\n",
    "\n",
    "                            # Head position detection based on jawline center\n",
    "                            if jaw_center_x < center_x - horizontal_threshold:\n",
    "                                position = 'left'\n",
    "                                if head_position_start_time is None:\n",
    "                                    head_position_start_time = time.time()\n",
    "                            elif jaw_center_x > center_x + horizontal_threshold:\n",
    "                                position = 'right'\n",
    "                                if head_position_start_time is None:\n",
    "                                    head_position_start_time = time.time()\n",
    "                            elif jaw_center_y < center_y - vertical_threshold:\n",
    "                                position = 'up'\n",
    "                                if head_position_start_time is None:\n",
    "                                    head_position_start_time = time.time()\n",
    "                            elif jaw_center_y > center_y + vertical_threshold:\n",
    "                                position = 'down'\n",
    "                                if head_position_start_time is None:\n",
    "                                    head_position_start_time = time.time()\n",
    "                            else:\n",
    "                                position = 'center'\n",
    "                                head_position_start_time = None\n",
    "\n",
    "                            # Debug print for detected position\n",
    "                            print(f\"Detected position: {position}\")\n",
    "\n",
    "                            # Only trigger alert if the head is turned for the entire duration\n",
    "                            if head_position_start_time and time.time() - head_position_start_time >= HEAD_POSITION_ALERT_SECONDS:\n",
    "                                if position in ['left']:\n",
    "                                    warning_message = \"Please look straight\"\n",
    "                                    warning_start_time = time.time()\n",
    "                                    speak(f\"Please look straight you are turning left.\")\n",
    "                                head_position_start_time = None\n",
    "                                \n",
    "                                if position in ['right']:\n",
    "                                    warning_message = \"Please look straight\"\n",
    "                                    warning_start_time = time.time()\n",
    "                                    speak(f\"Please look straight you are turning right.\")\n",
    "                                head_position_start_time = None\n",
    "                                \n",
    "                                if position in ['up']:\n",
    "                                    warning_message = \"Please look straight\"\n",
    "                                    warning_start_time = time.time()\n",
    "                                    speak(f\"Please look straight you are facing up.\")\n",
    "                                head_position_start_time = None\n",
    "                                \n",
    "            current_time = time.time()\n",
    "\n",
    "            # Update and display counts every 30 seconds\n",
    "            if current_time - count_update_time >= COUNT_INTERVAL:\n",
    "                count_update_time = current_time\n",
    "\n",
    "            # Trigger drowsiness alert if no blinking for a long duration\n",
    "            if current_time - last_blink_update_time >= DROWSY_ALERT_SECONDS:\n",
    "                warning_message = 'You are drowsy, please stay alert!'\n",
    "                warning_start_time = current_time\n",
    "                speak(\"You are drowsy, please stay alert.\")\n",
    "                \n",
    "                # Reset counters\n",
    "                blink_count = 0\n",
    "                yawn_count = 0\n",
    "\n",
    "            # Check if warning message should be updated\n",
    "            if warning_message and current_time - warning_start_time <= WARNING_DISPLAY_SECONDS:\n",
    "                cv2.putText(frame, warning_message, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                warning_message = \"\"\n",
    "\n",
    "            # Display the blink and yawn counts on the video feed\n",
    "            cv2.putText(frame, f\"Blink Count: {blink_count}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Yawn Count: {yawn_count}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Location: {location_text}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display head position message\n",
    "            if position != 'center':\n",
    "                cv2.putText(frame, f\"Head Position: {position.capitalize()}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "            cv2.imshow('Face Landmarks Detection', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167b954",
   "metadata": {},
   "source": [
    "# Blink code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad18cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "# Initialize MediaPipe Face Mesh and drawing utilities\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Eye Aspect Ratio (EAR) calculation\n",
    "def calculate_ear(eye_landmarks):\n",
    "    # Vertical eye landmarks (used for EAR calculation)\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    # Horizontal eye landmark\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    # EAR formula\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "# Indices for the left and right eye landmarks (from MediaPipe's 468 landmarks)\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "\n",
    "# Thresholds and consecutive frame count for blink detection\n",
    "EAR_THRESHOLD = 0.25\n",
    "CONSECUTIVE_FRAMES = 2\n",
    "blink_count = 0\n",
    "frame_counter = 0\n",
    "\n",
    "# Start the video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Flip the frame horizontally for a later selfie-view display\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Convert the BGR image to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame with MediaPipe Face Mesh\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Extract left and right eye landmarks\n",
    "            left_eye = np.array([(int(face_landmarks.landmark[i].x * frame.shape[1]),\n",
    "                                  int(face_landmarks.landmark[i].y * frame.shape[0])) for i in LEFT_EYE])\n",
    "            right_eye = np.array([(int(face_landmarks.landmark[i].x * frame.shape[1]),\n",
    "                                   int(face_landmarks.landmark[i].y * frame.shape[0])) for i in RIGHT_EYE])\n",
    "            \n",
    "            # Calculate EAR for both eyes\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            \n",
    "            # Check if EAR is below the threshold and increment frame counter\n",
    "            if ear < EAR_THRESHOLD:\n",
    "                frame_counter += 1\n",
    "            else:\n",
    "                if frame_counter >= CONSECUTIVE_FRAMES:\n",
    "                    blink_count += 1\n",
    "                    print(\"Blink detected!\")\n",
    "                frame_counter = 0\n",
    "            \n",
    "            # Draw the eye landmarks for visualization\n",
    "            for point in left_eye:\n",
    "                cv2.circle(frame, tuple(point), 2, (0, 255, 0), -1)\n",
    "            for point in right_eye:\n",
    "                cv2.circle(frame, tuple(point), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    # Display the blink count\n",
    "    cv2.putText(frame, f\"Blinks: {blink_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('Blink Detection', frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f430c10",
   "metadata": {},
   "source": [
    "# Head and blink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67aaa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define constants for EAR and MAR thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.7\n",
    "MOUTH_AR_CONSEC_FRAMES = 5\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = list(range(48, 68))  # Full mouth landmarks\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "position = 'center'\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(mouth):\n",
    "    A = dist.euclidean(mouth[2], mouth[6])  # Vertical distance\n",
    "    B = dist.euclidean(mouth[3], mouth[5])  # Vertical distance\n",
    "    C = dist.euclidean(mouth[0], mouth[4])  # Horizontal distance\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    # Calculate the average position of the jawline landmarks\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    # Calculate average position for the jawline\n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    # Get the center of the frame\n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    # Define thresholds for detecting left, right, up, and down positions\n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    # Determine head position\n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(mouth)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "                blink_frames = 0\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                yawn_frames += 1\n",
    "            else:\n",
    "                if yawn_frames >= MOUTH_AR_CONSEC_FRAMES:\n",
    "                    yawn_count += 1\n",
    "                yawn_frames = 0\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position.capitalize()}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    # Display current date and time\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    cv2.putText(frame, f'Time: {current_time}', (10, frame_height - 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    # Display current location\n",
    "    cv2.putText(frame, f'Location: {location_text}', (10, frame_height - 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a861b13",
   "metadata": {},
   "source": [
    "# Their code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e740dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codeee\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "import winsound\n",
    "from datetime import datetime\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "def toggle_fullscreen():\n",
    "    # Toggle fullscreen mode\n",
    "    if cv2.getWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN) == cv2.WINDOW_FULLSCREEN:\n",
    "        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "    else:\n",
    "        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Create a named window\n",
    "window_name = 'Driver State Analysis'\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Start in fullscreen mode\n",
    "cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Blink and Yawn Counters\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "frequent_blink_alert_count = 0\n",
    "frequent_yawn_alert_count = 0\n",
    "head_position_change_alert_count=0\n",
    "\n",
    "\n",
    "# Constants for blink and yawn detection\n",
    "EYE_AR_THRESH = 0.2\n",
    "EYE_AR_CONSEC_FRAMES = 2\n",
    "MOUTH_AR_THRESH = 0.7\n",
    "MOUTH_OPEN_CONSEC_FRAMES = 5\n",
    "\n",
    "# Initialize counters for consecutive frames\n",
    "COUNTER = 0\n",
    "yawn_counter = 0\n",
    "\n",
    "# Mouth open state flag\n",
    "mouth_open = False\n",
    "\n",
    "# Cooldown period for yawns in seconds\n",
    "yawn_cooldown_period = 5\n",
    "last_yawn_time = 0  # Tracks the last time a yawn was detected\n",
    "\n",
    "# Timer for blink count reset and alert\n",
    "start_time = time.time()\n",
    "reset_interval = 30  # Reset interval in seconds (30 seconds)\n",
    "blink_last_reset_time = start_time  \n",
    "frequent_blink_alert_reset_time = start_time\n",
    "#frequent_yawn_alert_reset_time = start_time\n",
    "head_position_change_alert_reset_time= start_time\n",
    "# New variables for frequent blinking alert\n",
    "alert_duration = 5  # Duration for alert message in seconds\n",
    "frequent_blink_alert_start_time = None  # Track the start time of the frequent blinking alert\n",
    "frequent_blink_alert_shown = False  # Flag to control frequent blinking alert message display\n",
    "\n",
    "# Variables for eyes closed alert\n",
    "eyes_closed_start_time = None  # Track when the eyes were first closed\n",
    "eyes_closed_alert_shown = False  # Flag to control the eyes closed alert message display\n",
    "eyes_closed_alert_duration = 5  # Duration to show the eyes closed alert in seconds\n",
    "\n",
    "# Timer for yawn count reset and alert\n",
    "yawn_start_time = time.time()  # Timer to track when to reset the yawn count\n",
    "frequent_yawn_alert_start_time = None  # Track the start time of the frequent yawning alert\n",
    "frequent_yawn_alert_shown = False  # Flag to control frequent yawning alert message display\n",
    "last_reset_time = None\n",
    "\n",
    "# Variables for \"Look at the road\" alert\n",
    "look_at_road_start_time = None  # Track the time when the person last looked forward\n",
    "look_at_road_alert_shown = False  # Flag to control the \"Look at the road\" alert message display\n",
    "look_at_road_alert_duration = 5  # Duration to show the \"Look at the road\" alert in seconds\n",
    "\n",
    "previous_position = \"Forward\"\n",
    "position_change_count = 0\n",
    "\n",
    "# Timer for head position change reset and alert\n",
    "head_position_change_start_time = time.time()  # Timer to track when to reset the position change count\n",
    "head_position_change_last_reset_time = None  # Track the last reset time\n",
    "head_position_change_alert_start_time = None  # Track the start time of the position change alert\n",
    "head_position_change_alert_shown = False  # Flag to control position change alert message display\n",
    "head_position_change_alert_duration = 5  # Duration to show the position change alert in seconds\n",
    "\n",
    "\n",
    "current_state = \"Awake\"\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = dist.euclidean(mouth[0], mouth[1])  # Upper lip to lower lip\n",
    "    C = dist.euclidean(mouth[2], mouth[3])  # Left corner to right corner of the mouth\n",
    "    mar = A / C\n",
    "    return mar\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    current_time = time.time()\n",
    "    start = time.time()\n",
    "\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = face_landmarks.landmark\n",
    "\n",
    "            # Correct indices for eyes\n",
    "            left_eye = [landmarks[i] for i in [33, 160, 158, 133, 153, 144]]\n",
    "            right_eye = [landmarks[i] for i in [362, 385, 387, 263, 373, 380]]\n",
    "\n",
    "            left_eye = np.array([(lm.x * img_w, lm.y * img_h) for lm in left_eye], dtype=np.float64)\n",
    "            right_eye = np.array([(lm.x * img_w, lm.y * img_h) for lm in right_eye], dtype=np.float64)\n",
    "\n",
    "            left_ear = eye_aspect_ratio(left_eye)\n",
    "            right_ear = eye_aspect_ratio(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            # Correct indices for mouth landmarks\n",
    "            mouth = [landmarks[i] for i in [13, 14, 78, 308]]\n",
    "            mouth = np.array([(lm.x * img_w, lm.y * img_h) for lm in mouth], dtype=np.float64)\n",
    "\n",
    "            mar = mouth_aspect_ratio(mouth)\n",
    "\n",
    "            # Head pose estimation\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    if idx == 1:\n",
    "                        nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                        nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "                    face_2d.append([x, y])\n",
    "                    face_3d.append([x, y, lm.z])\n",
    "\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            focal_length = 1 * img_w\n",
    "\n",
    "            cam_matrix = np.array([[focal_length, 0, img_h / 2],\n",
    "                                   [0, focal_length, img_w / 2],\n",
    "                                   [0, 0, 1]])\n",
    "\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "            rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "            x = angles[0] * 360\n",
    "            y = angles[1] * 360\n",
    "            z = angles[2] * 360\n",
    "\n",
    "            # Determine head pose and use corresponding eye aspect ratio threshold\n",
    "            if y < -17:\n",
    "                current_position = \"Looking Left\"\n",
    "            elif y > 17:\n",
    "                current_position = \"Looking Right\"\n",
    "            elif x < -15:\n",
    "                current_position = \"Looking Down\"\n",
    "            elif x > 19:\n",
    "                current_position= \"Looking Up\"\n",
    "            else:\n",
    "                current_position = \"Forward\"\n",
    "\n",
    "                # Update look_at_road_start_time when looking forward\n",
    "                look_at_road_start_time = current_time  # Reset the timer when looking forward\n",
    "                look_at_road_alert_shown = False  # Reset the alert flag\n",
    "\n",
    "           # Blink detection logic using the current threshold\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "                if eyes_closed_start_time is None:\n",
    "                    eyes_closed_start_time = time.time()\n",
    "                elif time.time() - eyes_closed_start_time > 5:  # Eyes closed for more than 5 seconds\n",
    "                    if not eyes_closed_alert_shown:\n",
    "                        eyes_closed_alert_shown = True\n",
    "                        eyes_closed_alert_start_time = time.time()\n",
    "                        \n",
    "            else:\n",
    "                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "                COUNTER = 0\n",
    "                eyes_closed_start_time = None  # Reset the eyes closed start time\n",
    "\n",
    "            # Yawn detection logic with the new reset mechanism\n",
    "            current_time = time.time()\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                yawn_counter += 1\n",
    "                if yawn_counter >= MOUTH_OPEN_CONSEC_FRAMES and not mouth_open:\n",
    "                    if current_time - last_yawn_time > yawn_cooldown_period:\n",
    "                        yawn_count += 1\n",
    "                        mouth_open = True\n",
    "                        last_yawn_time = current_time\n",
    "                        \n",
    "            else:\n",
    "                mouth_open = False\n",
    "                yawn_counter = 0\n",
    "\n",
    "               # Yawn count reset logic with a delay\n",
    "            if yawn_count >= 5:\n",
    "                if last_reset_time is None:\n",
    "                    last_reset_time = current_time  # Track the time when count reaches 5\n",
    "                elif current_time - last_reset_time >= 5:  # Wait for 2 seconds if last_reset_time is set\n",
    "                    yawn_count = 0  # Reset the count\n",
    "                    yawn_start_time = current_time  # Start a new 1-minute interval\n",
    "                    last_reset_time = None  # Reset the last_reset_time for future use\n",
    "            elif current_time - yawn_start_time >= 60:\n",
    "                yawn_count = 0\n",
    "                yawn_start_time = current_time\n",
    "\n",
    "                    # Check for position change (ignore changes to 'Forward')\n",
    "            if current_position != \"Forward\" and current_position != previous_position:\n",
    "                position_change_count += 1\n",
    "                previous_position = current_position  # Update the previous position\n",
    "\n",
    "            # Head position change count reset logic with a delay\n",
    "            if position_change_count >= 7:\n",
    "                if head_position_change_last_reset_time is None:\n",
    "                    head_position_change_last_reset_time = current_time  # Track the time when count reaches 7\n",
    "                elif current_time - head_position_change_last_reset_time >= 5:  # Wait for 5 seconds if last_reset_time is set\n",
    "                    position_change_count = 0  # Reset the count\n",
    "                    head_position_change_start_time = current_time  # Start a new 1-minute interval\n",
    "                    head_position_change_last_reset_time = None  # Reset the last_reset_time for future use\n",
    "            elif current_time - head_position_change_start_time >= 60:\n",
    "                position_change_count = 0\n",
    "                head_position_change_start_time = current_time\n",
    "\n",
    "\n",
    "\n",
    "            nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "            p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "            p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\n",
    "            \n",
    "            #cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "\n",
    "            # Check if the blink count exceeds 12 or 24\n",
    "            # Check if the blink count exceeds 12\n",
    "            if blink_count >= 13:\n",
    "                blink_count = 0  # Reset immediately\n",
    "                blink_last_reset_time = time.time()  # Start a new 30-second interval\n",
    "            elif time.time() - blink_last_reset_time >= reset_interval:\n",
    "                blink_count = 0\n",
    "                blink_last_reset_time = time.time()  # Start a new 30-second interval\n",
    "            \n",
    "            if blink_count in [12, 24]:\n",
    "                if not frequent_blink_alert_shown:\n",
    "                    frequent_blink_alert_start_time = time.time() \n",
    "                    frequent_blink_alert_count += 1 # Start the frequent blinking alert\n",
    "                    frequent_blink_alert_shown = True\n",
    "\n",
    "            # Display frequent blinking alert message if needed\n",
    "            if frequent_blink_alert_shown:\n",
    "                if time.time() - frequent_blink_alert_start_time <= alert_duration:  # Show the alert for the specified duration\n",
    "                    cv2.putText(image, \"Frequent Blinking Alert\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    cv2.putText(image, \"DROWSY\", (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 2)\n",
    "                else:\n",
    "                    frequent_blink_alert_shown = False  # Reset the flag to stop showing the alert\n",
    "                    \n",
    "            # Display eyes closed for too long alert message if needed\n",
    "            if eyes_closed_start_time is not None:\n",
    "                elapsed_time = time.time() - eyes_closed_start_time\n",
    "                if elapsed_time > eyes_closed_alert_duration:\n",
    "                    eyes_closed_alert_shown = True\n",
    "            else:\n",
    "                    eyes_closed_alert_shown = False\n",
    "                    #current_state=\"Awake\"\n",
    "\n",
    "            # Display eye closure alert message if needed\n",
    "            if eyes_closed_alert_shown:\n",
    "                cv2.putText(image, \"WAKE UP! WAKE UP!\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                current_state= \"Drowsy\"\n",
    "                cv2.putText(image, \"DROWSY\", (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 2)\n",
    "                winsound.Beep(2000,500)\n",
    "            else :\n",
    "                eyes_closed_alert_shown = False\n",
    "            if yawn_count >= 5:\n",
    "                if not frequent_yawn_alert_shown:\n",
    "                    frequent_yawn_alert_start_time = time.time() \n",
    "                    #frequent_yawn_alert_count += 1 # Start the frequent yawning alert\n",
    "                    frequent_yawn_alert_shown = True\n",
    "    # Display frequent yawning alert message if needed\n",
    "                if frequent_yawn_alert_shown:\n",
    "                        if time.time() - frequent_yawn_alert_start_time <= alert_duration:  # Show the alert for the specified duration\n",
    "                            cv2.putText(image, \"Frequent Yawning Detected!\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                            cv2.putText(image, \"FATIGUE\", (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 2)\n",
    "                        else:\n",
    "                            frequent_yawn_alert_shown = False\n",
    "                             # Stop showing the alert message\n",
    "            else:\n",
    "    # Reset the alert state if yawn count goes below 5\n",
    "                frequent_yawn_alert_shown = False\n",
    "\n",
    "            if time.time() - start_time >= reset_interval:\n",
    "                blink_count = 0\n",
    "                start_time = time.time()\n",
    "            # Check if the person has not looked forward for more than 15 seconds\n",
    "            if look_at_road_start_time is not None and current_time - look_at_road_start_time > 3:\n",
    "                if not look_at_road_alert_shown:\n",
    "                    look_at_road_alert_shown = True\n",
    "                    look_at_road_alert_start_time = current_time\n",
    "\n",
    "# Display the \"Look at the road\" alert message if needed\n",
    "            if look_at_road_alert_shown:\n",
    "                if time.time() - look_at_road_alert_start_time <= look_at_road_alert_duration:\n",
    "                    cv2.putText(image, \"Look at the Road!\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    cv2.putText(image, \"VISUAL COGNITIVE\", (100, 400), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 2)\n",
    "                    winsound.Beep(2000,100)\n",
    "                else:\n",
    "                    look_at_road_alert_shown = False \n",
    "                    current_state=\"Awake\" # Stop showing the alert message\n",
    "            # Check if the head position change count reaches 7\n",
    "            if position_change_count >= 7:\n",
    "                if not head_position_change_alert_shown:\n",
    "                    head_position_change_alert_start_time = time.time()  # Start the head position change alert\n",
    "                    head_position_change_alert_count+=1\n",
    "                    \n",
    "                    head_position_change_alert_shown = True\n",
    "\n",
    "# Display head position change alert message if needed\n",
    "            if head_position_change_alert_shown:\n",
    "                if time.time() - head_position_change_alert_start_time <= head_position_change_alert_duration:  # Show the alert for the specified duration\n",
    "                    cv2.putText(image, \"Distraction Detected!\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    cv2.putText(image, \"VISUAL COGNITIVE\", (100, 400), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 2)\n",
    "                else:\n",
    "                    head_position_change_alert_shown = False  # Stop showing the alert message\n",
    "\n",
    " \n",
    "\n",
    "            # Reset the frequent blinking alert count every minute\n",
    "            if current_time - frequent_blink_alert_reset_time >= 60 or eyes_closed_alert_shown :\n",
    "               frequent_blink_alert_count = 0  # Reset the frequent blink alert count\n",
    "               frequent_blink_alert_reset_time = time.time()\n",
    "               \n",
    "            #if frequent_blink_alert_count >= 2:\n",
    "            #    current_state = \"Drowsy\"  \n",
    "            # Update the reset time  \n",
    "\n",
    "            #if head_position_change_alert_count>= 2:\n",
    "            #    current_state = \"Visual Cognitive\"  \n",
    "\n",
    "            #if current_time - frequent_yawn_alert_reset_time >= 120:\n",
    "            #    frequent_yawn_alert_count = 0  # Reset the frequent blink alert count\n",
    "            #    frequent_yawn_alert_reset_time = time.time()  # Update the reset time  \n",
    "\n",
    "            # Reset the frequent blinking alert count every minute\n",
    "            if current_time - head_position_change_alert_reset_time >= 60 or head_position_change_alert_shown:\n",
    "                head_position_change_alert_count= 0  # Reset the frequent blink alert count\n",
    "                head_position_change_alert_reset_time = time.time()  # Update the reset time              \n",
    "            #cv2.putText(image, f\"Blink Count: {blink_count}\", (30, 150),\n",
    "                        #cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 100, 100), 2)\n",
    "            #cv2.putText(image, f\"Yawn Count: {yawn_count}\", (30, 180),\n",
    "                        #cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 250, 0), 2)\n",
    "            #cv2.putText(image, f\"Head Pose: {current_position}\", (30, 210),\n",
    "                        #cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 105, 0), 2)\n",
    "            #cv2.putText(image, f\"Head Position Change Count: {position_change_count}\", (30, 240),\n",
    "                    #cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 100, 0), 2)\n",
    "            #cv2.putText(image, f\"Frequent Blink Alerts: {frequent_blink_alert_count}\", (30, 280), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            #cv2.putText(image, f\"Frequent Yawn Alerts: {frequent_yawn_alert_count}\", (30, 300), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            #cv2.putText(image, f\"Head Position Change Alerts: {head_position_change_alert_count}\", (30, 320), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            #cv2.putText(image, f'State: {current_state}', (10, img_h - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    end = time.time()\n",
    "\n",
    "    totalTime = end - start\n",
    "\n",
    "    if totalTime > 0:\n",
    "                fps = 1 / totalTime\n",
    "    else:\n",
    "                fps = 0  # Set fps to 0 or handle this case as needed\n",
    "    #cv2.putText(image, f'FPS: {int(fps)}', (500, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Draw the face mesh landmarks (all 468 points)\n",
    "    #mp_drawing.draw_landmarks(\n",
    "                #image=image,\n",
    "                #landmark_list=face_landmarks,\n",
    "                #connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                #landmark_drawing_spec=drawing_spec,\n",
    "                #connection_drawing_spec=drawing_spec\n",
    "#            )\n",
    "\n",
    "    #cv2.putText(image, f'FPS: {int(fps)}', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    cv2.putText(image,f\"{current_datetime}\",(10,img_h - 10),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),2)\n",
    "\n",
    "    cv2.imshow(window_name, image)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dce099",
   "metadata": {},
   "source": [
    "# Pupil detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# Define constants\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "EYE_AR_THRESH = 0.25  # Adjust this threshold as needed\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to calculate Eye Aspect Ratio (EAR)\n",
    "def calculate_ear(eye_landmarks):\n",
    "    # Example distances; adjust as needed for accuracy\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "# Initialize blink detection variables\n",
    "blink_count = 0\n",
    "blink_frames = 0\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract eye landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "            # Calculate EAR for both eyes\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "                blink_frames = 0\n",
    "\n",
    "            # Draw pupil marks\n",
    "            cv2.circle(frame, pupil_left, 5, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, pupil_right, 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Display blink count\n",
    "            cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Pupil Detection and Blink Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04ce7c",
   "metadata": {},
   "source": [
    "# Head position and blink with voice command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b2e99-38c0-4913-90db-ef8cfece5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define constants for EAR and MAR thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.5  # Adjusted threshold\n",
    "MOUTH_AR_CONSEC_FRAMES = 15  # Adjusted for better detection\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for drowsiness detection\n",
    "HEAD_POSITION_TIME_THRESHOLD = 10  # 10 seconds for head position alert\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [78, 95, 88, 191, 80, 82, 13, 311, 308, 402, 317, 14]  # Updated for MediaPipe\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "position = 'center'\n",
    "eyes_closed_time = None\n",
    "drowsy_command_played = False\n",
    "head_position_start_time = None\n",
    "look_at_road_command_played = False\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(mouth_landmarks):\n",
    "    A = dist.euclidean(mouth_landmarks[1], mouth_landmarks[7])  # Upper to lower lip\n",
    "    B = dist.euclidean(mouth_landmarks[3], mouth_landmarks[5])  # Left to right corner\n",
    "    mar = A / B\n",
    "    return mar\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to run voice command in a separate thread\n",
    "def thread_play_voice_command(message):\n",
    "    t = threading.Thread(target=play_voice_command, args=(message,))\n",
    "    t.start()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(mouth)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "\n",
    "                # Start counting the duration of eye closure\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                # Check if eyes are closed for more than the threshold\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD:\n",
    "                    if not drowsy_command_played:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_command_played = True\n",
    "\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                drowsy_command_played = False\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                yawn_frames += 1\n",
    "            else:\n",
    "                if yawn_frames >= MOUTH_AR_CONSEC_FRAMES:\n",
    "                    yawn_count += 1\n",
    "                yawn_frames = 0\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "            # Check head position for voice command\n",
    "            if position != 'center':\n",
    "                if head_position_start_time is None:\n",
    "                    head_position_start_time = time.time()\n",
    "\n",
    "                if time.time() - head_position_start_time >= HEAD_POSITION_TIME_THRESHOLD:\n",
    "                    # Continuously play the voice command if head is not in the center\n",
    "                    thread_play_voice_command(\"Look at the road\")\n",
    "                    look_at_road_command_played = True\n",
    "\n",
    "            else:\n",
    "                head_position_start_time = None\n",
    "                look_at_road_command_played = False\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "            # Draw pupil marks (hide these by commenting out the lines if not needed)\n",
    "            # cv2.circle(frame, pupil_left, 5, (0, 255, 0), -1)\n",
    "            # cv2.circle(frame, pupil_right, 5, (0, 255, 0), -1)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position.capitalize()}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    # Display current date and time\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    cv2.putText(frame, f'Time: {current_time}', (10, frame_height - 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    # Display current location\n",
    "    cv2.putText(frame, f'Location: {location_text}', (10, frame_height - 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a913e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\intern_proj\\NEWN\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define constants for EAR and MAR thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.5  # Adjusted threshold\n",
    "MOUTH_AR_CONSEC_FRAMES = 15  # Adjusted for better detection\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for drowsiness detection\n",
    "HEAD_POSITION_TIME_THRESHOLD = 10  # 10 seconds for head position alert\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [78, 95, 88, 191, 80, 82, 13, 311, 308, 402, 317, 14]  # Updated for MediaPipe\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "position = 'center'\n",
    "eyes_closed_time = None\n",
    "drowsy_command_played = False\n",
    "head_position_start_time = None\n",
    "look_at_road_command_played = False\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(mouth_landmarks):\n",
    "    A = dist.euclidean(mouth_landmarks[1], mouth_landmarks[7])  # Upper to lower lip\n",
    "    B = dist.euclidean(mouth_landmarks[3], mouth_landmarks[5])  # Left to right corner\n",
    "    mar = A / B\n",
    "    return mar\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to run voice command in a separate thread\n",
    "def thread_play_voice_command(message):\n",
    "    t = threading.Thread(target=play_voice_command, args=(message,))\n",
    "    t.start()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(mouth)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "\n",
    "                # Start counting the duration of eye closure\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                # Check if eyes are closed for more than the threshold\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD:\n",
    "                    if not drowsy_command_played:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_command_played = True\n",
    "\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                drowsy_command_played = False\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                yawn_frames += 1\n",
    "            else:\n",
    "                if yawn_frames >= MOUTH_AR_CONSEC_FRAMES:\n",
    "                    yawn_count += 1\n",
    "                yawn_frames = 0\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "            # Check head position for voice command\n",
    "            if position != 'center':\n",
    "                if head_position_start_time is None:\n",
    "                    head_position_start_time = time.time()\n",
    "\n",
    "                if time.time() - head_position_start_time >= HEAD_POSITION_TIME_THRESHOLD:\n",
    "                    if not look_at_road_command_played:\n",
    "                        thread_play_voice_command(\"Look at the road\")\n",
    "                        look_at_road_command_played = True\n",
    "\n",
    "            else:\n",
    "                head_position_start_time = None\n",
    "                look_at_road_command_played = False\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "            # Draw pupil marks\n",
    "            cv2.circle(frame, pupil_left, 5, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, pupil_right, 5, (0, 255, 0), -1)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position.capitalize()}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    # Display current date and time\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    cv2.putText(frame, f'Time: {current_time}', (10, frame_height - 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    # Display current location\n",
    "    cv2.putText(frame, f'Location: {location_text}', (10, frame_height - 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75404ccb",
   "metadata": {},
   "source": [
    "# Yawn detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8463ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\intern_proj\\NEWN\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to calculate the Mouth Aspect Ratio (MAR)\n",
    "def calculate_mar(landmarks):\n",
    "    top_lip = landmarks[13:15]  # Top lip points\n",
    "    bottom_lip = landmarks[14:16]  # Bottom lip points\n",
    "\n",
    "    # Calculate the vertical distance\n",
    "    vertical_distance = np.linalg.norm(np.array(top_lip[0]) - np.array(bottom_lip[0]))\n",
    "\n",
    "    # Calculate the horizontal distance\n",
    "    left_corner = landmarks[78]  # Left corner of the mouth\n",
    "    right_corner = landmarks[308]  # Right corner of the mouth\n",
    "    horizontal_distance = np.linalg.norm(np.array(left_corner) - np.array(right_corner))\n",
    "\n",
    "    # MAR calculation\n",
    "    mar = vertical_distance / horizontal_distance\n",
    "    return mar\n",
    "\n",
    "# Thresholds\n",
    "YAWN_THRESHOLD = 0.6  # Threshold for detecting a yawn\n",
    "CLOSE_THRESHOLD = 0.4  # Threshold for detecting mouth close after a yawn\n",
    "COOLDOWN_PERIOD = 20  # Number of frames to wait before allowing another yawn count\n",
    "\n",
    "# Start the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "yawn_count = 0\n",
    "mouth_open = False  # Track if the mouth was open in the previous frame\n",
    "cooldown = 0  # Cooldown timer to prevent multiple yawn counts\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect face landmarks\n",
    "    result = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        for face_landmarks in result.multi_face_landmarks:\n",
    "            landmarks = []\n",
    "            for lm in face_landmarks.landmark:\n",
    "                landmarks.append([int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])])\n",
    "\n",
    "            # Calculate the MAR\n",
    "            mar = calculate_mar(landmarks)\n",
    "\n",
    "            # Check if MAR exceeds the yawn threshold (mouth is open)\n",
    "            if mar > YAWN_THRESHOLD:\n",
    "                if not mouth_open and cooldown == 0:\n",
    "                    mouth_open = True\n",
    "            # Check if MAR is below the close threshold (mouth is closed)\n",
    "            elif mar < CLOSE_THRESHOLD:\n",
    "                if mouth_open:\n",
    "                    yawn_count += 1\n",
    "                    mouth_open = False\n",
    "                    cooldown = COOLDOWN_PERIOD  # Start cooldown period\n",
    "                    cv2.putText(frame, \"Yawning!\", (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Decrement the cooldown timer if it's active\n",
    "            if cooldown > 0:\n",
    "                cooldown -= 1\n",
    "\n",
    "            # Draw only the mouth landmarks\n",
    "            mouth_landmarks = [13, 14, 78, 308]\n",
    "            for idx in mouth_landmarks:\n",
    "                x, y = landmarks[idx]\n",
    "                cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "    # Display yawn count\n",
    "    cv2.putText(frame, f\"Yawn Count: {yawn_count}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Yawn Detection', frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451828dd",
   "metadata": {},
   "source": [
    "# Blink, yawn and head position with commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a933aa4-1af1-42d1-bd68-6386b9b50b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands played only once no exceptions are displayed\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define constants for EAR, MAR, and thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.6  # Yawn threshold\n",
    "MOUTH_AR_CLOSE_THRESH = 0.4  # Mouth close threshold\n",
    "MOUTH_AR_CONSEC_FRAMES = 15\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for drowsiness detection\n",
    "HEAD_POSITION_TIME_THRESHOLD = 3  # 10 seconds for head position alert\n",
    "COOLDOWN_PERIOD = 20  # Cooldown period for yawn counting\n",
    "\n",
    "# Timer and yawn count settings\n",
    "YAWN_LIMIT = 3  # Limit for yawn count to trigger fatigue alert\n",
    "TIMER_DURATION = 40  # Timer duration in seconds\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [78, 95, 88, 191, 80, 82, 13, 311, 308, 402, 317, 14]\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "cooldown = 0  # Cooldown timer to prevent multiple yawn counts\n",
    "mouth_open = False  # Track if the mouth was open in the previous frame\n",
    "position = 'center'\n",
    "eyes_closed_time = None\n",
    "drowsy_command_played = False\n",
    "head_position_start_time = None\n",
    "look_at_road_command_played = False\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(landmarks):\n",
    "    top_lip = landmarks[13:15]  # Top lip points\n",
    "    bottom_lip = landmarks[14:16]  # Bottom lip points\n",
    "\n",
    "    # Calculate the vertical distance\n",
    "    vertical_distance = np.linalg.norm(np.array(top_lip[0]) - np.array(bottom_lip[0]))\n",
    "\n",
    "    # Calculate the horizontal distance\n",
    "    left_corner = landmarks[78]  # Left corner of the mouth\n",
    "    right_corner = landmarks[308]  # Right corner of the mouth\n",
    "    horizontal_distance = np.linalg.norm(np.array(left_corner) - np.array(right_corner))\n",
    "\n",
    "    # MAR calculation\n",
    "    mar = vertical_distance / horizontal_distance\n",
    "    return mar\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to run voice command in a separate thread\n",
    "def thread_play_voice_command(message):\n",
    "    t = threading.Thread(target=play_voice_command, args=(message,))\n",
    "    t.start()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "yawn_timer_start = time.time()  # To track the 30-second window for yawn counts\n",
    "\n",
    "# Initialize a flag to track if the fatigue command has been played\n",
    "fatigue_command_played = False\n",
    "\n",
    "# ... (other parts of the code remain unchanged)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(landmarks)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "\n",
    "                # Start counting the duration of eye closure\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                # Check if eyes are closed for more than the threshold\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD:\n",
    "                    # Continuously play the voice command while eyes are closed\n",
    "                    if not drowsy_command_played:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_command_played = True\n",
    "\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                drowsy_command_played = False\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                if not mouth_open and cooldown == 0:\n",
    "                    mouth_open = True\n",
    "            elif mar < MOUTH_AR_CLOSE_THRESH:\n",
    "                if mouth_open:\n",
    "                    yawn_count += 1\n",
    "                    mouth_open = False\n",
    "                    cooldown = COOLDOWN_PERIOD  # Start cooldown period\n",
    "\n",
    "            # Decrease the cooldown timer\n",
    "            if cooldown > 0:\n",
    "                cooldown -= 1\n",
    "\n",
    "            # Check if yawn count exceeds the threshold\n",
    "            if yawn_count >= YAWN_LIMIT:\n",
    "                # Play the voice command immediately\n",
    "                thread_play_voice_command(\"You look fatigued! Take rest\")\n",
    "                \n",
    "                cv2.putText(frame, f'Fatigue state', (10, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                # Reset the yawn count, timer, and fatigue command flag immediately\n",
    "                yawn_count = 0\n",
    "                yawn_timer_start = time.time()\n",
    "                fatigue_command_played = False  # Reset the fatigue command flag for future use\n",
    "\n",
    "            # Timer logic for yawn count reset, independent of the yawn threshold\n",
    "            if time.time() - yawn_timer_start >= TIMER_DURATION:\n",
    "                yawn_timer_start = time.time()\n",
    "                yawn_count = 0\n",
    "                fatigue_command_played = False  # Ensure the fatigue command can be played again\n",
    "\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "            # Check head position for voice command\n",
    "            if position != 'center':\n",
    "                if not look_at_road_command_played:  # Check if the command hasn't been played yet\n",
    "                    if head_position_start_time is None:\n",
    "                        head_position_start_time = time.time()\n",
    "            \n",
    "                    if time.time() - head_position_start_time >= HEAD_POSITION_TIME_THRESHOLD:\n",
    "                        thread_play_voice_command(\"Look at the road\")\n",
    "                        look_at_road_command_played = True  # Set flag to True to avoid replaying\n",
    "            \n",
    "                        cv2.putText(frame, f'Cognitive distraction', (10, 30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Reset flag and time when head returns to center\n",
    "                head_position_start_time = None\n",
    "                look_at_road_command_played = False\n",
    "\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display pupil markers\n",
    "    cv2.circle(frame, pupil_left, 3, (0, 255, 0), -1)\n",
    "    cv2.circle(frame, pupil_right, 3, (0, 255, 0), -1)\n",
    "\n",
    "    # Display date, time, and location\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d-%m-%Y')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "\n",
    "    cv2.putText(frame, f'{date_str}', (frame_width - 200, frame_height - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{time_str}', (frame_width - 200, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{location_text}', (10, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15849bdb-1d80-4a20-8561-4c2781e9cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands with text in display\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define constants for EAR, MAR, and thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.6  # Yawn threshold\n",
    "MOUTH_AR_CLOSE_THRESH = 0.4  # Mouth close threshold\n",
    "MOUTH_AR_CONSEC_FRAMES = 15\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for drowsiness detection\n",
    "HEAD_POSITION_TIME_THRESHOLD = 3  # 10 seconds for head position alert\n",
    "COOLDOWN_PERIOD = 20  # Cooldown period for yawn counting\n",
    "\n",
    "# Timer and yawn count settings\n",
    "YAWN_LIMIT = 3  # Limit for yawn count to trigger fatigue alert\n",
    "TIMER_DURATION = 40  # Timer duration in seconds\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [78, 95, 88, 191, 80, 82, 13, 311, 308, 402, 317, 14]\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "cooldown = 0  # Cooldown timer to prevent multiple yawn counts\n",
    "mouth_open = False  # Track if the mouth was open in the previous frame\n",
    "position = 'center'\n",
    "eyes_closed_time = None\n",
    "drowsy_command_played = False\n",
    "head_position_start_time = None\n",
    "look_at_road_command_played = False\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(landmarks):\n",
    "    top_lip = landmarks[13:15]  # Top lip points\n",
    "    bottom_lip = landmarks[14:16]  # Bottom lip points\n",
    "\n",
    "    # Calculate the vertical distance\n",
    "    vertical_distance = np.linalg.norm(np.array(top_lip[0]) - np.array(bottom_lip[0]))\n",
    "\n",
    "    # Calculate the horizontal distance\n",
    "    left_corner = landmarks[78]  # Left corner of the mouth\n",
    "    right_corner = landmarks[308]  # Right corner of the mouth\n",
    "    horizontal_distance = np.linalg.norm(np.array(left_corner) - np.array(right_corner))\n",
    "\n",
    "    # MAR calculation\n",
    "    mar = vertical_distance / horizontal_distance\n",
    "    return mar\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to run voice command in a separate thread\n",
    "def thread_play_voice_command(message):\n",
    "    t = threading.Thread(target=play_voice_command, args=(message,))\n",
    "    t.start()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "yawn_timer_start = time.time()  # To track the 30-second window for yawn counts\n",
    "\n",
    "# Initialize a flag to track if the fatigue command has been played\n",
    "fatigue_command_played = False\n",
    "\n",
    "# ... (other parts of the code remain unchanged)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(landmarks)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "\n",
    "                # Start counting the duration of eye closure\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                # Check if eyes are closed for more than the threshold\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD:\n",
    "                    # Continuously play the voice command while eyes are closed\n",
    "                    if not drowsy_command_played:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_command_played = True\n",
    "                        \n",
    "                    else:\n",
    "                        # Re-play the command if it's already playing\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        cv2.putText(frame, f'Drowsy state', (10, 30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                drowsy_command_played = False\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                if not mouth_open and cooldown == 0:\n",
    "                    mouth_open = True\n",
    "            elif mar < MOUTH_AR_CLOSE_THRESH:\n",
    "                if mouth_open:\n",
    "                    yawn_count += 1\n",
    "                    mouth_open = False\n",
    "                    cooldown = COOLDOWN_PERIOD  # Start cooldown period\n",
    "\n",
    "            # Decrease the cooldown timer\n",
    "            if cooldown > 0:\n",
    "                cooldown -= 1\n",
    "\n",
    "            # Check if yawn count exceeds the threshold\n",
    "            if yawn_count >= YAWN_LIMIT:\n",
    "                # Play the voice command immediately\n",
    "                thread_play_voice_command(\"You look fatigued! Take rest\")\n",
    "                \n",
    "                cv2.putText(frame, f'Fatigue state', (10, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                # Reset the yawn count, timer, and fatigue command flag immediately\n",
    "                yawn_count = 0\n",
    "                yawn_timer_start = time.time()\n",
    "                fatigue_command_played = False  # Reset the fatigue command flag for future use\n",
    "\n",
    "            # Timer logic for yawn count reset, independent of the yawn threshold\n",
    "            if time.time() - yawn_timer_start >= TIMER_DURATION:\n",
    "                yawn_timer_start = time.time()\n",
    "                yawn_count = 0\n",
    "                fatigue_command_played = False  # Ensure the fatigue command can be played again\n",
    "\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "            # Check head position for voice command\n",
    "            if position != 'center':\n",
    "                if head_position_start_time is None:\n",
    "                    head_position_start_time = time.time()\n",
    "\n",
    "                if time.time() - head_position_start_time >= HEAD_POSITION_TIME_THRESHOLD:\n",
    "                    thread_play_voice_command(\"Look at the road\")\n",
    "                    look_at_road_command_played = True\n",
    "                    \n",
    "                    cv2.putText(frame, f'Cognitive distraction', (10, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            else:\n",
    "                head_position_start_time = None\n",
    "                look_at_road_command_played = False\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display pupil markers\n",
    "    cv2.circle(frame, pupil_left, 3, (0, 255, 0), -1)\n",
    "    cv2.circle(frame, pupil_right, 3, (0, 255, 0), -1)\n",
    "\n",
    "    # Display date, time, and location\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d-%m-%Y')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "\n",
    "    cv2.putText(frame, f'{date_str}', (frame_width - 200, frame_height - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{time_str}', (frame_width - 200, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{location_text}', (10, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556c94f-dd2d-449a-b93f-ee544f91e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect code for yawn blink and head position with command\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define constants for EAR, MAR, and thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.6  # Yawn threshold\n",
    "MOUTH_AR_CLOSE_THRESH = 0.4  # Mouth close threshold\n",
    "MOUTH_AR_CONSEC_FRAMES = 15\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for drowsiness detection\n",
    "HEAD_POSITION_TIME_THRESHOLD = 3  # 10 seconds for head position alert\n",
    "COOLDOWN_PERIOD = 20  # Cooldown period for yawn counting\n",
    "\n",
    "# Timer and yawn count settings\n",
    "YAWN_LIMIT = 3  # Limit for yawn count to trigger fatigue alert\n",
    "TIMER_DURATION = 40  # Timer duration in seconds\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [78, 95, 88, 191, 80, 82, 13, 311, 308, 402, 317, 14]\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "cooldown = 0  # Cooldown timer to prevent multiple yawn counts\n",
    "mouth_open = False  # Track if the mouth was open in the previous frame\n",
    "position = 'center'\n",
    "eyes_closed_time = None\n",
    "drowsy_command_played = False\n",
    "head_position_start_time = None\n",
    "look_at_road_command_played = False\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(landmarks):\n",
    "    top_lip = landmarks[13:15]  # Top lip points\n",
    "    bottom_lip = landmarks[14:16]  # Bottom lip points\n",
    "\n",
    "    # Calculate the vertical distance\n",
    "    vertical_distance = np.linalg.norm(np.array(top_lip[0]) - np.array(bottom_lip[0]))\n",
    "\n",
    "    # Calculate the horizontal distance\n",
    "    left_corner = landmarks[78]  # Left corner of the mouth\n",
    "    right_corner = landmarks[308]  # Right corner of the mouth\n",
    "    horizontal_distance = np.linalg.norm(np.array(left_corner) - np.array(right_corner))\n",
    "\n",
    "    # MAR calculation\n",
    "    mar = vertical_distance / horizontal_distance\n",
    "    return mar\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to run voice command in a separate thread\n",
    "def thread_play_voice_command(message):\n",
    "    t = threading.Thread(target=play_voice_command, args=(message,))\n",
    "    t.start()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "yawn_timer_start = time.time()  # To track the 30-second window for yawn counts\n",
    "\n",
    "# Initialize a flag to track if the fatigue command has been played\n",
    "fatigue_command_played = False\n",
    "\n",
    "# ... (other parts of the code remain unchanged)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(landmarks)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "\n",
    "                # Start counting the duration of eye closure\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                # Check if eyes are closed for more than the threshold\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD:\n",
    "                    # Continuously play the voice command while eyes are closed\n",
    "                    if not drowsy_command_played:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_command_played = True\n",
    "                        \n",
    "                    else:\n",
    "                        # Re-play the command if it's already playing\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        cv2.putText(frame, f'Drowsy state', (10, 30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                drowsy_command_played = False\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                if not mouth_open and cooldown == 0:\n",
    "                    mouth_open = True\n",
    "            elif mar < MOUTH_AR_CLOSE_THRESH:\n",
    "                if mouth_open:\n",
    "                    yawn_count += 1\n",
    "                    mouth_open = False\n",
    "                    cooldown = COOLDOWN_PERIOD  # Start cooldown period\n",
    "\n",
    "            # Decrease the cooldown timer\n",
    "            if cooldown > 0:\n",
    "                cooldown -= 1\n",
    "\n",
    "            # Check if yawn count exceeds the threshold\n",
    "            if yawn_count >= YAWN_LIMIT:\n",
    "                # Play the voice command immediately\n",
    "                thread_play_voice_command(\"You look fatigued! Take rest\")\n",
    "\n",
    "                # Reset the yawn count, timer, and fatigue command flag immediately\n",
    "                yawn_count = 0\n",
    "                yawn_timer_start = time.time()\n",
    "                fatigue_command_played = False  # Reset the fatigue command flag for future use\n",
    "\n",
    "            # Timer logic for yawn count reset, independent of the yawn threshold\n",
    "            if time.time() - yawn_timer_start >= TIMER_DURATION:\n",
    "                yawn_timer_start = time.time()\n",
    "                yawn_count = 0\n",
    "                fatigue_command_played = False  # Ensure the fatigue command can be played again\n",
    "\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "            # Check head position for voice command\n",
    "            if position != 'center':\n",
    "                if head_position_start_time is None:\n",
    "                    head_position_start_time = time.time()\n",
    "\n",
    "                if time.time() - head_position_start_time >= HEAD_POSITION_TIME_THRESHOLD:\n",
    "                    thread_play_voice_command(\"Look at the road\")\n",
    "                    look_at_road_command_played = True\n",
    "\n",
    "            else:\n",
    "                head_position_start_time = None\n",
    "                look_at_road_command_played = False\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display pupil markers\n",
    "    #cv2.circle(frame, pupil_left, 3, (0, 255, 0), -1)\n",
    "    #cv2.circle(frame, pupil_right, 3, (0, 255, 0), -1)\n",
    "\n",
    "    # Display date, time, and location\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d-%m-%Y')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "\n",
    "    cv2.putText(frame, f'{date_str}', (frame_width - 200, frame_height - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{time_str}', (frame_width - 200, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{location_text}', (10, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e839bcb4-d86c-40b8-b0d9-6e5770bc5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7aa569-f9b4-4c19-97f6-dbd496c52c46",
   "metadata": {},
   "source": [
    "# Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a050e7c-1910-4818-9486-7cc14c45f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only eye with mail\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyttsx3\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Email configuration\n",
    "SENDER_EMAIL = \"karthiiiksk@gmail.com\"  # Change this to your email\n",
    "SENDER_PASSWORD = \"bpql sxcu hpkt mqdp\"\n",
    "RECIPIENT_EMAIL = \"srinivasakarthik4522@gmail.com\"  # Change this to the recipient's email\n",
    "\n",
    "# Define constants for EAR and thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3  # Number of consecutive frames to consider a blink\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for voice alert\n",
    "EMAIL_ALERT_THRESHOLD = 15  # 15 seconds for email alert\n",
    "\n",
    "# Email sending function\n",
    "def send_email():\n",
    "    try:\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = SENDER_EMAIL\n",
    "        msg['To'] = RECIPIENT_EMAIL\n",
    "        msg['Subject'] = \"Alert: Person might have fainted!\"\n",
    "        \n",
    "        body = \"The person has closed their eyes for more than 15 seconds and may have fainted.\"\n",
    "        msg.attach(MIMEText(body, 'plain'))\n",
    "        \n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(SENDER_EMAIL, SENDER_PASSWORD)\n",
    "        \n",
    "        server.sendmail(SENDER_EMAIL, RECIPIENT_EMAIL, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"Alert email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send email: {e}\")\n",
    "\n",
    "# Function to calculate Eye Aspect Ratio (EAR)\n",
    "def calculate_ear(eye_landmarks):\n",
    "    A = np.linalg.norm(eye_landmarks[1] - eye_landmarks[5])\n",
    "    B = np.linalg.norm(eye_landmarks[2] - eye_landmarks[4])\n",
    "    C = np.linalg.norm(eye_landmarks[0] - eye_landmarks[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_frames = 0\n",
    "blink_count = 0\n",
    "eyes_closed_time = None\n",
    "voice_alert_played = False\n",
    "email_alert_sent = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract left and right eye landmarks (example indices for eyes)\n",
    "            left_eye = landmarks[[33, 160, 158, 133, 153, 144]]\n",
    "            right_eye = landmarks[[362, 385, 387, 263, 373, 380]]\n",
    "\n",
    "            # Calculate EAR for both eyes\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "                # Start timing how long the eyes are closed\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                # Voice alert after 5 seconds of closed eyes\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD and not voice_alert_played:\n",
    "                    play_voice_command(\"You are feeling drowsy! Stay alert.\")\n",
    "                    voice_alert_played = True\n",
    "\n",
    "                # Email alert after 15 seconds of closed eyes\n",
    "                if time.time() - eyes_closed_time >= EMAIL_ALERT_THRESHOLD and not email_alert_sent:\n",
    "                    send_email()\n",
    "                    email_alert_sent = True\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                voice_alert_played = False\n",
    "                email_alert_sent = False\n",
    "\n",
    "    # Display EAR and blink count\n",
    "    cv2.putText(frame, f'EAR: {ear:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Eye Drowsiness and Blink Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089271b-0665-436a-aa7b-9b65e013bf95",
   "metadata": {},
   "source": [
    "# Blink Yawn Head Mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b5f95-8090-4ecc-8836-59ba4cbaddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Email configuration\n",
    "SENDER_EMAIL = \"karthiiiksk@gmail.com\"  # Change this to your email\n",
    "SENDER_PASSWORD = \"bpql sxcu hpkt mqdp\"  \n",
    "RECIPIENT_EMAIL = \"srinivasakarthik4522@gmail.com\"  # Change this to the recipient's email\n",
    "\n",
    "# Define constants for EAR, MAR, and thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.6  # Yawn threshold\n",
    "MOUTH_AR_CLOSE_THRESH = 0.4  # Mouth close threshold\n",
    "MOUTH_AR_CONSEC_FRAMES = 15\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for voice alert\n",
    "EMAIL_ALERT_THRESHOLD = 15  # 15 seconds for email alert\n",
    "HEAD_POSITION_TIME_THRESHOLD = 3  # 10 seconds for head position alert\n",
    "COOLDOWN_PERIOD = 20  # Cooldown period for yawn counting\n",
    "\n",
    "# Timer and yawn count settings\n",
    "YAWN_LIMIT = 3  # Limit for yawn count to trigger fatigue alert\n",
    "TIMER_DURATION = 40  # Timer duration in seconds\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [78, 95, 88, 191, 80, 82, 13, 311, 308, 402, 317, 14]\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "cooldown = 0  # Cooldown timer to prevent multiple yawn counts\n",
    "mouth_open = False  # Track if the mouth was open in the previous frame\n",
    "position = 'center'\n",
    "eyes_closed_time = None\n",
    "drowsy_command_played = False\n",
    "head_position_start_time = None\n",
    "look_at_road_command_played = False\n",
    "voice_alert_played = False\n",
    "email_alert_sent = False\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "def send_email():\n",
    "    try:\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = SENDER_EMAIL\n",
    "        msg['To'] = RECIPIENT_EMAIL\n",
    "        msg['Subject'] = \"Alert: Person might have fainted!\"\n",
    "        \n",
    "        body = \"The person has closed their eyes for more than 15 seconds and may have fainted.\"\n",
    "        msg.attach(MIMEText(body, 'plain'))\n",
    "        \n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(SENDER_EMAIL, SENDER_PASSWORD)\n",
    "        \n",
    "        server.sendmail(SENDER_EMAIL, RECIPIENT_EMAIL, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"Alert email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send email: {e}\")\n",
    "        \n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(landmarks):\n",
    "    top_lip = landmarks[13:15]  # Top lip points\n",
    "    bottom_lip = landmarks[14:16]  # Bottom lip points\n",
    "\n",
    "    # Calculate the vertical distance\n",
    "    vertical_distance = np.linalg.norm(np.array(top_lip[0]) - np.array(bottom_lip[0]))\n",
    "\n",
    "    # Calculate the horizontal distance\n",
    "    left_corner = landmarks[78]  # Left corner of the mouth\n",
    "    right_corner = landmarks[308]  # Right corner of the mouth\n",
    "    horizontal_distance = np.linalg.norm(np.array(left_corner) - np.array(right_corner))\n",
    "\n",
    "    # MAR calculation\n",
    "    mar = vertical_distance / horizontal_distance\n",
    "    return mar\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to run voice command in a separate thread\n",
    "def thread_play_voice_command(message):\n",
    "    t = threading.Thread(target=play_voice_command, args=(message,))\n",
    "    t.start()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "yawn_timer_start = time.time()  # To track the 30-second window for yawn counts\n",
    "\n",
    "# Initialize a flag to track if the fatigue command has been played\n",
    "fatigue_command_played = False\n",
    "\n",
    "# ... (other parts of the code remain unchanged)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(landmarks)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "\n",
    "                # Start counting the duration of eye closure\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD:\n",
    "                    # Continuously play the voice command while eyes are closed\n",
    "                    if not drowsy_command_played:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_command_played = True\n",
    "                    else:\n",
    "                        # Re-play the command if it's already playing\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        cv2.putText(frame, f'Drowsy state', (10, 30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                        \n",
    "                        if time.time() - eyes_closed_time >= EMAIL_ALERT_THRESHOLD and not email_alert_sent:\n",
    "                            print(\"Attempting to send email...\")\n",
    "                            send_email()\n",
    "                            email_alert_sent = True\n",
    "\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                drowsy_command_played = False\n",
    "                email_alert_sent = False\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                if not mouth_open and cooldown == 0:\n",
    "                    mouth_open = True\n",
    "            elif mar < MOUTH_AR_CLOSE_THRESH:\n",
    "                if mouth_open:\n",
    "                    yawn_count += 1\n",
    "                    mouth_open = False\n",
    "                    cooldown = COOLDOWN_PERIOD  # Start cooldown period\n",
    "\n",
    "            # Decrease the cooldown timer\n",
    "            if cooldown > 0:\n",
    "                cooldown -= 1\n",
    "\n",
    "            # Check if yawn count exceeds the threshold\n",
    "            if yawn_count >= YAWN_LIMIT:\n",
    "                # Play the voice command immediately\n",
    "                thread_play_voice_command(\"You look fatigued! Take rest\")\n",
    "\n",
    "                # Reset the yawn count, timer, and fatigue command flag immediately\n",
    "                yawn_count = 0\n",
    "                yawn_timer_start = time.time()\n",
    "                fatigue_command_played = False  # Reset the fatigue command flag for future use\n",
    "\n",
    "            # Timer logic for yawn count reset, independent of the yawn threshold\n",
    "            if time.time() - yawn_timer_start >= TIMER_DURATION:\n",
    "                yawn_timer_start = time.time()\n",
    "                yawn_count = 0\n",
    "                fatigue_command_played = False  # Ensure the fatigue command can be played again\n",
    "\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "            # Check head position for voice command\n",
    "            if position != 'center':\n",
    "                if head_position_start_time is None:\n",
    "                    head_position_start_time = time.time()\n",
    "\n",
    "                if time.time() - head_position_start_time >= HEAD_POSITION_TIME_THRESHOLD:\n",
    "                    thread_play_voice_command(\"Look at the road\")\n",
    "                    look_at_road_command_played = True\n",
    "\n",
    "            else:\n",
    "                head_position_start_time = None\n",
    "                look_at_road_command_played = False\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display pupil markers\n",
    "    cv2.circle(frame, pupil_left, 3, (0, 255, 0), -1)\n",
    "    cv2.circle(frame, pupil_right, 3, (0, 255, 0), -1)\n",
    "\n",
    "    # Display date, time, and location\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d-%m-%Y')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "\n",
    "    cv2.putText(frame, f'{date_str}', (frame_width - 200, frame_height - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{time_str}', (frame_width - 200, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'{location_text}', (10, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b98f2c-7a62-4692-b6f4-b59dca912c18",
   "metadata": {},
   "source": [
    "# Icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65a18c-6748-4d85-86d8-241bc80324d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyttsx3\n",
    "import threading\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Email configuration\n",
    "SENDER_EMAIL = \"karthiiiksk@gmail.com\"  # Change this to your email\n",
    "SENDER_PASSWORD = \"bpql sxcu hpkt mqdp\"  \n",
    "RECIPIENT_EMAIL = \"srinivasakarthik4522@gmail.com\"  # Change this to the recipient's email\n",
    "\n",
    "# Define constants for EAR, MAR, and thresholds\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "MOUTH_AR_THRESH = 0.6  # Yawn threshold\n",
    "MOUTH_AR_CLOSE_THRESH = 0.4  # Mouth close threshold\n",
    "MOUTH_AR_CONSEC_FRAMES = 15\n",
    "DROWSINESS_TIME_THRESHOLD = 5  # 5 seconds for voice alert\n",
    "EMAIL_ALERT_THRESHOLD = 15  # 15 seconds for email alert\n",
    "HEAD_POSITION_TIME_THRESHOLD = 3  # 10 seconds for head position alert\n",
    "COOLDOWN_PERIOD = 20  # Cooldown period for yawn counting\n",
    "\n",
    "# Timer and yawn count settings\n",
    "YAWN_LIMIT = 3  # Limit for yawn count to trigger fatigue alert\n",
    "TIMER_DURATION = 40  # Timer duration in seconds\n",
    "\n",
    "# Indices for landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH = [78, 95, 88, 191, 80, 82, 13, 311, 308, 402, 317, 14]\n",
    "JAWLINE = list(range(0, 17))  # Jawline (from 0 to 16)\n",
    "\n",
    "# Initialize counters and time tracking\n",
    "blink_count = 0\n",
    "yawn_count = 0\n",
    "blink_frames = 0\n",
    "yawn_frames = 0\n",
    "cooldown = 0  # Cooldown timer to prevent multiple yawn counts\n",
    "mouth_open = False  # Track if the mouth was open in the previous frame\n",
    "position = 'center'\n",
    "eyes_closed_time = None\n",
    "drowsy_command_played = False\n",
    "head_position_start_time = None\n",
    "look_at_road_command_played = False\n",
    "voice_alert_played = False\n",
    "email_alert_sent = False\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "\n",
    "# Fetch location using IP-based service\n",
    "def get_current_location():\n",
    "    ip_info_url = \"http://ipinfo.io/json\"\n",
    "    response = requests.get(ip_info_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    city = data.get('city', 'Unknown City')\n",
    "    region = data.get('region', 'Unknown Region')\n",
    "    country = data.get('country', 'Unknown Country')\n",
    "    \n",
    "    location = f\"{city}, {region}, {country}\"\n",
    "    \n",
    "    return location\n",
    "\n",
    "location_text = get_current_location()\n",
    "\n",
    "def send_email():\n",
    "    try:\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = SENDER_EMAIL\n",
    "        msg['To'] = RECIPIENT_EMAIL\n",
    "        msg['Subject'] = \"Alert: Person might have fainted!\"\n",
    "        \n",
    "        body = \"The person has closed their eyes for more than 15 seconds and may have fainted.\"\n",
    "        msg.attach(MIMEText(body, 'plain'))\n",
    "        \n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(SENDER_EMAIL, SENDER_PASSWORD)\n",
    "        \n",
    "        server.sendmail(SENDER_EMAIL, RECIPIENT_EMAIL, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"Alert email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send email: {e}\")\n",
    "        \n",
    "# Define EAR and MAR calculation functions\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vert1 = dist.euclidean(eye_landmarks[1], eye_landmarks[5])\n",
    "    vert2 = dist.euclidean(eye_landmarks[2], eye_landmarks[4])\n",
    "    horz = dist.euclidean(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vert1 + vert2) / (2.0 * horz)\n",
    "    return ear\n",
    "\n",
    "def calculate_mar(landmarks):\n",
    "    top_lip = landmarks[13:15]  # Top lip points\n",
    "    bottom_lip = landmarks[14:16]  # Bottom lip points\n",
    "\n",
    "    # Calculate the vertical distance\n",
    "    vertical_distance = np.linalg.norm(np.array(top_lip[0]) - np.array(bottom_lip[0]))\n",
    "\n",
    "    # Calculate the horizontal distance\n",
    "    left_corner = landmarks[78]  # Left corner of the mouth\n",
    "    right_corner = landmarks[308]  # Right corner of the mouth\n",
    "    horizontal_distance = np.linalg.norm(np.array(left_corner) - np.array(right_corner))\n",
    "\n",
    "    # MAR calculation\n",
    "    mar = vertical_distance / horizontal_distance\n",
    "    return mar\n",
    "\n",
    "def get_head_position(jawline, frame_width, frame_height):\n",
    "    jawline_x = jawline[:, 0]\n",
    "    jawline_y = jawline[:, 1]\n",
    "    \n",
    "    jaw_center_x = np.mean(jawline_x)\n",
    "    jaw_center_y = np.mean(jawline_y)\n",
    "    \n",
    "    center_x = frame_width / 2\n",
    "    center_y = frame_height / 2\n",
    "    \n",
    "    horizontal_threshold = 60  # Threshold for detecting horizontal movement\n",
    "    vertical_threshold = 50    # Threshold for detecting vertical movement\n",
    "    \n",
    "    if jaw_center_x < center_x - horizontal_threshold:\n",
    "        return 'left'\n",
    "    elif jaw_center_x > center_x + horizontal_threshold:\n",
    "        return 'right'\n",
    "    elif jaw_center_y < center_y - vertical_threshold:\n",
    "        return 'up'\n",
    "    elif jaw_center_y > center_y + vertical_threshold:\n",
    "        return 'down'\n",
    "    else:\n",
    "        return 'center'\n",
    "\n",
    "# Function to calculate pupil center\n",
    "def get_pupil_center(eye_landmarks):\n",
    "    x_coords = [pt[0] for pt in eye_landmarks]\n",
    "    y_coords = [pt[1] for pt in eye_landmarks]\n",
    "    center_x = int(sum(x_coords) / len(x_coords))\n",
    "    center_y = int(sum(y_coords) / len(y_coords))\n",
    "    return (center_x, center_y)\n",
    "\n",
    "# Function to play voice command\n",
    "def play_voice_command(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to run voice command in a separate thread\n",
    "def thread_play_voice_command(message):\n",
    "    t = threading.Thread(target=play_voice_command, args=(message,))\n",
    "    t.start()\n",
    "\n",
    "# Open video capture with 720p resolution\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1280\n",
    "height = 720\n",
    "fps = 30\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "cv2.namedWindow('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Face Landmarks Detection', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Timer variables for yawn detection\n",
    "timer_start = time.time()  # To track the 30-second interval\n",
    "yawn_timer_start = time.time()  # To track the 30-second window for yawn counts\n",
    "\n",
    "# Initialize a flag to track if the fatigue command has been played\n",
    "fatigue_command_played = False\n",
    "\n",
    "# ... (other parts of the code remain unchanged)\n",
    "\n",
    "# Load images for blink, yawn, and head position\n",
    "drowsy_img = cv2.imread('C:/Users/DELL/Downloads/blink1_icon.png', cv2.IMREAD_UNCHANGED)\n",
    "fatigue_img = cv2.imread('C:/Users/DELL/Downloads/yawn1_icon.png', cv2.IMREAD_UNCHANGED)\n",
    "look_straight_img = cv2.imread('C:/Users/DELL/Downloads/head3_icon.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "def overlay_image_alpha(background, overlay, position):\n",
    "    x, y = position\n",
    "    bg_h, bg_w = background.shape[:2]\n",
    "    h, w = overlay.shape[:2]\n",
    "\n",
    "    # Ensure the overlay fits within the frame\n",
    "    if x + w > bg_w:\n",
    "        x = bg_w - w\n",
    "    if y + h > bg_h:\n",
    "        y = bg_h - h\n",
    "    \n",
    "    # Extract the alpha channel\n",
    "    if x < 0 or y < 0 or x + w > bg_w or y + h > bg_h:\n",
    "        raise ValueError(\"Overlay image exceeds background dimensions.\")\n",
    "\n",
    "    alpha_overlay = overlay[:, :, 3] / 255.0\n",
    "    alpha_background = 1.0 - alpha_overlay\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        background[y:y+h, x:x+w, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                                       alpha_background * background[y:y+h, x:x+w, c])\n",
    "\n",
    "    return background\n",
    "\n",
    "\n",
    "# Inside your while loop\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    # Reset image display flags\n",
    "    drowsy_img_displayed = False\n",
    "    fatigue_img_displayed = False\n",
    "    look_straight_img_displayed = False\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = np.array([(lm.x * frame_width, lm.y * frame_height) for lm in face_landmarks.landmark])\n",
    "\n",
    "            # Extract landmarks\n",
    "            left_eye = landmarks[LEFT_EYE]\n",
    "            right_eye = landmarks[RIGHT_EYE]\n",
    "            mouth = landmarks[MOUTH]\n",
    "            jawline = landmarks[JAWLINE]\n",
    "\n",
    "            # Calculate EAR and MAR\n",
    "            left_ear = calculate_ear(left_eye)\n",
    "            right_ear = calculate_ear(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = calculate_mar(landmarks)\n",
    "\n",
    "            # Blink detection logic\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                blink_frames += 1\n",
    "\n",
    "                if eyes_closed_time is None:\n",
    "                    eyes_closed_time = time.time()\n",
    "\n",
    "                if time.time() - eyes_closed_time >= DROWSINESS_TIME_THRESHOLD:\n",
    "                    if not drowsy_command_played:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_command_played = True\n",
    "                        \n",
    "                    else:\n",
    "                        thread_play_voice_command(\"You are feeling drowsy! Stay alert\")\n",
    "                        drowsy_img_displayed = True  # Show drowsy image\n",
    "                        cv2.putText(frame, f'Drowsy state', (30, 400),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                        if time.time() - eyes_closed_time >= EMAIL_ALERT_THRESHOLD and not email_alert_sent:\n",
    "                            print(\"Attempting to send email...\")\n",
    "                            send_email()\n",
    "                            email_alert_sent = True\n",
    "\n",
    "            else:\n",
    "                if blink_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "\n",
    "                blink_frames = 0\n",
    "                eyes_closed_time = None\n",
    "                drowsy_command_played = False\n",
    "                email_alert_sent = False\n",
    "\n",
    "            # Yawn detection logic\n",
    "            if mar > MOUTH_AR_THRESH:\n",
    "                if not mouth_open and cooldown == 0:\n",
    "                    mouth_open = True\n",
    "            elif mar < MOUTH_AR_CLOSE_THRESH:\n",
    "                if mouth_open:\n",
    "                    yawn_count += 1\n",
    "                    mouth_open = False\n",
    "                    cooldown = COOLDOWN_PERIOD  # Start cooldown period\n",
    "\n",
    "            # Decrease the cooldown timer\n",
    "            if cooldown > 0:\n",
    "                cooldown -= 1\n",
    "\n",
    "            # Check if yawn count exceeds the threshold\n",
    "            if yawn_count >= YAWN_LIMIT:\n",
    "                if not fatigue_command_played:\n",
    "                    thread_play_voice_command(\"You look fatigued! Take rest\")\n",
    "                    cv2.putText(frame, f'Fatigue state', (30, 400),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    fatigue_command_played = True\n",
    "                    fatigue_img_displayed = True  # Show fatigue image\n",
    "\n",
    "                yawn_count = 0\n",
    "                yawn_timer_start = time.time()\n",
    "                fatigue_command_played = False  # Reset the fatigue command flag\n",
    "\n",
    "            # Timer logic for yawn count reset, independent of the yawn threshold\n",
    "            if time.time() - yawn_timer_start >= TIMER_DURATION:\n",
    "                yawn_timer_start = time.time()\n",
    "                yawn_count = 0\n",
    "                fatigue_command_played = False\n",
    "\n",
    "            # Calculate head position\n",
    "            position = get_head_position(jawline, frame_width, frame_height)\n",
    "\n",
    "            # Check head position for voice command\n",
    "            if position != 'center':\n",
    "                if head_position_start_time is None:\n",
    "                    head_position_start_time = time.time()\n",
    "\n",
    "                if time.time() - head_position_start_time >= HEAD_POSITION_TIME_THRESHOLD:\n",
    "                    thread_play_voice_command(\"Look at the road\")\n",
    "                    cv2.putText(frame, f'Cognitive Distraction', (30, 400),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    look_at_road_command_played = True\n",
    "                       \n",
    "                    look_straight_img_displayed = True  # Show head position image\n",
    "\n",
    "            else:\n",
    "                head_position_start_time = None\n",
    "                look_at_road_command_played = False\n",
    "\n",
    "            # Calculate pupil centers\n",
    "            pupil_left = get_pupil_center(left_eye)\n",
    "            pupil_right = get_pupil_center(right_eye)\n",
    "\n",
    "    # Display blink and yawn counts\n",
    "    cv2.putText(frame, f'Blinks: {blink_count}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Yawns: {yawn_count}', (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display head position\n",
    "    cv2.putText(frame, f'Head Position: {position}', (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display pupil markers\n",
    "    cv2.circle(frame, pupil_left, 3, (0, 255, 0), -1)\n",
    "    cv2.circle(frame, pupil_right, 3, (0, 255, 0), -1)\n",
    "\n",
    "    # Display date, time, and location\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d-%m-%Y')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "\n",
    "    cv2.putText(frame, f'{date_str}', (frame_width - 200, frame_height - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f'{time_str}', (frame_width - 200, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f'{location_text}', (10, frame_height - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Overlay images based on flags\n",
    "    if drowsy_img_displayed:\n",
    "        # Get frame and overlay image dimensions\n",
    "        frame_h, frame_w = frame.shape[:2]\n",
    "        overlay_h, overlay_w = drowsy_img.shape[:2]\n",
    "    \n",
    "        # Resize the overlay if it exceeds the frame dimensions\n",
    "        if overlay_w > frame_w or overlay_h > frame_h:\n",
    "            scale_factor = min(frame_w / overlay_w, frame_h / overlay_h)\n",
    "            drowsy_img = cv2.resize(drowsy_img, (int(overlay_w * scale_factor), int(overlay_h * scale_factor)))\n",
    "    \n",
    "        # Now, overlay the image after resizing (if needed)\n",
    "        frame = overlay_image_alpha(frame, drowsy_img, (1100, 10))\n",
    "\n",
    "    \n",
    "    if fatigue_img_displayed:\n",
    "        frame = overlay_image_alpha(frame, fatigue_img, (1100, 10))\n",
    "    \n",
    "    # Inside your main processing loop, before overlaying the image\n",
    "    if look_straight_img_displayed:\n",
    "        # Get frame and overlay image dimensions\n",
    "        frame_h, frame_w = frame.shape[:2]\n",
    "        overlay_h, overlay_w = look_straight_img.shape[:2]\n",
    "    \n",
    "        # Resize the overlay if it exceeds the frame dimensions\n",
    "        if overlay_w > frame_w or overlay_h > frame_h:\n",
    "            scale_factor = min(frame_w / overlay_w, frame_h / overlay_h)\n",
    "            look_straight_img = cv2.resize(look_straight_img, (int(overlay_w * scale_factor), int(overlay_h * scale_factor)))\n",
    "    \n",
    "        # Now, overlay the image after resizing (if needed)\n",
    "        frame = overlay_image_alpha(frame, look_straight_img, (1100, 10))\n",
    "\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Face Landmarks Detection', frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233afd05-ca11-4831-81bd-6e014c8c152c",
   "metadata": {},
   "source": [
    "# Posture detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c00f1-f269-4a88-81c1-5d97a7b7dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a8f14-1dcb-408a-aa84-435685ae0e9d",
   "metadata": {},
   "source": [
    "# Adaptive cruise control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc95c50-edaa-45d8-b6c8-0215d21e1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Load the YOLOv5 model pre-trained on the COCO dataset (which includes 'car', 'motorcycle', and 'truck' detection)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Open video file for video capture\n",
    "video_path = 'C:/Users/DELL/Downloads/lane_vid.mp4'  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the original frame rate of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the known sizes (in meters) for car, motorcycle, and truck\n",
    "KNOWN_CAR_WIDTH = 1.8  # Average width of a car in meters\n",
    "KNOWN_BIKE_WIDTH = 0.8  # Average width of a motorcycle in meters\n",
    "KNOWN_TRUCK_WIDTH = 2.5  # Average width of a truck in meters\n",
    "\n",
    "FOCAL_LENGTH = 700  # Adjust this value based on the camera's calibration\n",
    "\n",
    "# Distance threshold in meters\n",
    "DISTANCE_THRESHOLD = 10  # Adjust this to define how close a vehicle should be for a warning\n",
    "\n",
    "# Function to estimate distance using pinhole camera model\n",
    "def estimate_distance(bbox_width, object_width):\n",
    "    \"\"\"\n",
    "    Estimate the distance based on the size of the bounding box using a pinhole camera model.\n",
    "    \"\"\"\n",
    "    # Using the pinhole camera model: distance = (real_width * focal_length) / apparent_width\n",
    "    distance = (object_width * FOCAL_LENGTH) / bbox_width\n",
    "    return distance\n",
    "\n",
    "# Function to simulate braking\n",
    "def apply_brakes():\n",
    "    print(\"Emergency Brake Applied!\")  # Simulated braking action\n",
    "\n",
    "# Real-time object detection and distance estimation\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame to reduce processing time (optional)\n",
    "    frame = cv2.resize(frame, (640, 360))  # Resize to 640x360 for faster processing\n",
    "\n",
    "    # Detect objects in the current frame using YOLOv5\n",
    "    results = model(frame)\n",
    "\n",
    "    # Process the results to detect 'car', 'motorcycle', and 'truck'\n",
    "    for result in results.xyxy[0]:  # Iterate through bounding boxes\n",
    "        x1, y1, x2, y2, conf, class_id = result.tolist()\n",
    "        label = model.names[int(class_id)]\n",
    "\n",
    "        if label in ['car', 'motorcycle', 'truck']:  # Check for car, motorcycle, and truck\n",
    "            # Calculate the width of the bounding box\n",
    "            bbox_width = x2 - x1\n",
    "        \n",
    "            # Set the known width based on the detected object\n",
    "            if label == 'car':\n",
    "                object_width = KNOWN_CAR_WIDTH\n",
    "            elif label == 'motorcycle':\n",
    "                object_width = KNOWN_BIKE_WIDTH\n",
    "            elif label == 'truck':\n",
    "                object_width = KNOWN_TRUCK_WIDTH\n",
    "        \n",
    "            # Estimate the distance to the object using the known width\n",
    "            distance = estimate_distance(bbox_width, object_width)\n",
    "        \n",
    "            # Only display bounding box and distance if the object is below the threshold\n",
    "            if distance < DISTANCE_THRESHOLD:\n",
    "                # Draw a bounding box around the detected object\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        \n",
    "                # Display the distance on the frame\n",
    "                cv2.putText(frame, f\"{label.capitalize()} Distance: {distance:.2f}m\", (int(x1), int(y1) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        \n",
    "                # Trigger the braking system if the object is too close\n",
    "                if distance < 2:\n",
    "                    apply_brakes()\n",
    "                    print(\"Apply Brake\")\n",
    "\n",
    "    # Display the video feed with detections\n",
    "    cv2.imshow('AEB System', frame)\n",
    "\n",
    "    # Control the frame rate to match the original video speed\n",
    "    if cv2.waitKey(int(1000 / fps)) & 0xFF == ord('q'):  # Delay adjusted to video FPS\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e054c6-80d3-4991-a40d-c6f1c124a72c",
   "metadata": {},
   "source": [
    "# Cigar detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9173c8-f090-497e-84bc-401f305965ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good\n",
    "import torch\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Function to speak the warning in a separate thread\n",
    "def speak_warning():\n",
    "    engine.say(\"Don't smoke inside the car\")\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Load YOLOv5 model (replace the path with your best.pt)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='C:/Users/DELL/yolov5/runs/train/exp28/weights/best.pt')\n",
    "\n",
    "# Set confidence threshold for detections\n",
    "model.conf = 0.45  # Adjust the confidence threshold if needed\n",
    "\n",
    "# Open webcam or video feed\n",
    "cap = cv2.VideoCapture(0)  # 0 for webcam, or provide path to video file\n",
    "\n",
    "# Create a flag to prevent multiple threads from speaking the warning simultaneously\n",
    "warning_thread = None\n",
    "\n",
    "frame_count = 0\n",
    "inference_interval = 3  # Run YOLO inference every 3 frames\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "    # Run inference only on every nth frame\n",
    "    if frame_count % inference_interval == 0:\n",
    "        results = model(frame)\n",
    "        labels = results.xyxyn[0][:, -1].cpu().numpy()  # Get the labels of detected objects\n",
    "        names = results.names  # Get names of the labels (e.g., 'cigar')\n",
    "        \n",
    "        # Extract bounding boxes and confidence scores\n",
    "        boxes = results.xyxy[0].cpu().numpy()  # Get the bounding boxes (x1, y1, x2, y2, confidence, class)\n",
    "\n",
    "        # Loop through the detections\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2, conf, cls = box  # Unpack the bounding box\n",
    "            label = names[int(cls)]  # Get the label name\n",
    "\n",
    "            # Draw the bounding box on the frame if 'cigar' is detected\n",
    "            if label == 'cigar':\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)  # Draw the bounding box\n",
    "                cv2.putText(frame, f'{label} {conf:.2f}', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Check for cigar detection to trigger voice command\n",
    "        if any(names[int(label)] == 'cigar' for label in labels):\n",
    "            if warning_thread is None or not warning_thread.is_alive():\n",
    "                warning_thread = threading.Thread(target=speak_warning)\n",
    "                warning_thread.start()\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('Smoke Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcef7a-c31e-4207-8cfc-a0e07527a44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
